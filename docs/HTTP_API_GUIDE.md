# ğŸŒ Crawl4AI MCP HTTPã‚µãƒ¼ãƒãƒ¼ å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

Crawl4AI MCP ã‚µãƒ¼ãƒãƒ¼ã¯ã€FastMCPã®StreamableHTTPãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä½¿ç”¨ã—ã¦HTTPã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªAPIã‚µãƒ¼ãƒãƒ¼ã¨ã—ã¦å‹•ä½œã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¨™æº–çš„ãªHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ç›´æ¥MCPãƒ„ãƒ¼ãƒ«ã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚

## ğŸš€ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ–¹æ³•

### æ–¹æ³•1: å°‚ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰

```bash
# ã‚·ãƒ³ãƒ—ãƒ«èµ·å‹•ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ›ã‚¹ãƒˆã®ã¿ï¼‰
./run_http_server.sh

# å¤–éƒ¨ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§èµ·å‹•
./run_http_server.sh --external

# ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ãƒˆã§èµ·å‹•
./run_http_server.sh --port 8080

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•
./run_http_server.sh --log-level DEBUG
```

### æ–¹æ³•2: Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆç›´æ¥å®Ÿè¡Œ

```bash
# åŸºæœ¬èµ·å‹•
python run_http_server.py

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
python run_http_server.py --host 0.0.0.0 --port 8000 --log-level INFO
```

### æ–¹æ³•3: MCPã‚µãƒ¼ãƒãƒ¼ç›´æ¥å®Ÿè¡Œ

```bash
# HTTPãƒ¢ãƒ¼ãƒ‰
python -m crawl4ai_mcp.server --transport streamable-http --host 127.0.0.1 --port 8000

# å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
python -m crawl4ai_mcp.server --transport http --host 0.0.0.0 --port 8000
```

## ğŸ”Œ HTTPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

### åŸºæœ¬æƒ…å ±

- **ãƒ™ãƒ¼ã‚¹URL**: `http://127.0.0.1:8000` (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
- **ãƒ—ãƒ­ãƒˆã‚³ãƒ«**: HTTP/1.1
- **ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—**: `application/json`
- **èªè¨¼**: ä¸è¦

### ä¸»è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

| ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ | ãƒ¡ã‚½ãƒƒãƒ‰ | èª¬æ˜ |
|-------------|---------|------|
| `/` | GET | ã‚µãƒ¼ãƒãƒ¼æƒ…å ±å–å¾— |
| `/mcp/tools` | POST | åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ä¸€è¦§ |
| `/mcp/tools/{tool_name}` | POST | ç‰¹å®šãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œ |
| `/mcp/prompts` | POST | åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§ |
| `/mcp/prompts/{prompt_name}` | POST | ç‰¹å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å®Ÿè¡Œ |
| `/mcp/resources` | POST | åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹ä¸€è¦§ |
| `/mcp/resources/{resource_uri}` | POST | ç‰¹å®šãƒªã‚½ãƒ¼ã‚¹ã®å–å¾— |

## ğŸ› ï¸ ä¸»è¦ãƒ„ãƒ¼ãƒ«ä¸€è¦§

### Webã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°
- `crawl_url` - Webãƒšãƒ¼ã‚¸ã®ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º
- `deep_crawl_site` - ã‚µã‚¤ãƒˆå…¨ä½“ã®æ·±åº¦ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°
- `extract_structured_data` - æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
- `intelligent_extract` - AIé§†å‹•ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ

### YouTubeå‡¦ç†
- `extract_youtube_transcript` - YouTubeå‹•ç”»ã®å­—å¹•æŠ½å‡º
- `batch_extract_youtube_transcripts` - è¤‡æ•°å‹•ç”»ã®ä¸€æ‹¬å‡¦ç†
- `get_youtube_video_info` - å‹•ç”»æƒ…å ±ã®å–å¾—

### ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
- `process_file` - PDFã€Officeã€ZIPç­‰ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
- `get_supported_file_formats` - ã‚µãƒãƒ¼ãƒˆå½¢å¼ã®ç¢ºèª

### æ¤œç´¢æ©Ÿèƒ½
- `search_google` - Googleæ¤œç´¢ã®å®Ÿè¡Œ
- `batch_search_google` - è¤‡æ•°ã‚¯ã‚¨ãƒªã®ä¸€æ‹¬æ¤œç´¢
- `search_and_crawl` - æ¤œç´¢çµæœã®ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°

### è¨­å®šãƒ»æƒ…å ±
- `get_llm_config_info` - LLMè¨­å®šæƒ…å ±ã®å–å¾—

## ğŸ“ ä½¿ç”¨ä¾‹

### 1. ã‚µãƒ¼ãƒãƒ¼æƒ…å ±å–å¾—

```bash
curl -X GET http://127.0.0.1:8000/
```

```json
{
  "name": "crawl4ai-mcp",
  "version": "1.0.0",
  "capabilities": {
    "tools": true,
    "prompts": true,
    "resources": true
  }
}
```

### 2. ãƒ„ãƒ¼ãƒ«ä¸€è¦§å–å¾—

```bash
curl -X POST http://127.0.0.1:8000/mcp/tools \
  -H "Content-Type: application/json" \
  -d '{}'
```

### 3. Webãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°

```bash
curl -X POST http://127.0.0.1:8000/mcp/tools/crawl_url \
  -H "Content-Type: application/json" \
  -d '{
    "arguments": {
      "url": "https://example.com",
      "generate_markdown": true,
      "extract_media": false
    }
  }'
```

### 4. YouTubeå­—å¹•æŠ½å‡º

```bash
curl -X POST http://127.0.0.1:8000/mcp/tools/extract_youtube_transcript \
  -H "Content-Type: application/json" \
  -d '{
    "arguments": {
      "url": "https://www.youtube.com/watch?v=VIDEO_ID",
      "languages": ["ja", "en"],
      "include_timestamps": true
    }
  }'
```

### 5. Googleæ¤œç´¢

```bash
curl -X POST http://127.0.0.1:8000/mcp/tools/search_google \
  -H "Content-Type: application/json" \
  -d '{
    "arguments": {
      "query": "Python programming tutorial",
      "num_results": 5,
      "language": "en"
    }
  }'
```

### 6. ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†

```bash
curl -X POST http://127.0.0.1:8000/mcp/tools/process_file \
  -H "Content-Type: application/json" \
  -d '{
    "arguments": {
      "url": "https://example.com/document.pdf",
      "max_size_mb": 50
    }
  }'
```

## ğŸ Pythonã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¾‹

### åŸºæœ¬çš„ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
import aiohttp
import asyncio
import json

class Crawl4AIMCPClient:
    def __init__(self, base_url="http://127.0.0.1:8000"):
        self.base_url = base_url
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def call_tool(self, tool_name, arguments):
        async with self.session.post(
            f"{self.base_url}/mcp/tools/{tool_name}",
            json={"arguments": arguments}
        ) as resp:
            return await resp.json()

# ä½¿ç”¨ä¾‹
async def main():
    async with Crawl4AIMCPClient() as client:
        # Webãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°
        result = await client.call_tool("crawl_url", {
            "url": "https://example.com",
            "generate_markdown": True
        })
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        # YouTubeå­—å¹•æŠ½å‡º
        result = await client.call_tool("extract_youtube_transcript", {
            "url": "https://www.youtube.com/watch?v=VIDEO_ID",
            "languages": ["ja", "en"]
        })
        print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())
```

### é«˜åº¦ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¾‹

```python
import aiohttp
import asyncio
from typing import Dict, Any, List

class AdvancedCrawl4AIMCPClient:
    def __init__(self, base_url="http://127.0.0.1:8000", timeout=30):
        self.base_url = base_url.rstrip('/')
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(timeout=self.timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_tools(self) -> List[Dict[str, Any]]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        async with self.session.post(f"{self.base_url}/mcp/tools") as resp:
            data = await resp.json()
            return data.get('tools', [])
    
    async def crawl_webpage(self, url: str, **kwargs) -> Dict[str, Any]:
        """Webãƒšãƒ¼ã‚¸ã‚’ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°"""
        arguments = {"url": url, **kwargs}
        return await self.call_tool("crawl_url", arguments)
    
    async def extract_youtube_transcript(self, url: str, languages=None, **kwargs) -> Dict[str, Any]:
        """YouTubeå­—å¹•ã‚’æŠ½å‡º"""
        if languages is None:
            languages = ["ja", "en"]
        arguments = {"url": url, "languages": languages, **kwargs}
        return await self.call_tool("extract_youtube_transcript", arguments)
    
    async def search_google(self, query: str, num_results=5, **kwargs) -> Dict[str, Any]:
        """Googleæ¤œç´¢ã‚’å®Ÿè¡Œ"""
        arguments = {"query": query, "num_results": num_results, **kwargs}
        return await self.call_tool("search_google", arguments)
    
    async def process_file(self, url: str, **kwargs) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
        arguments = {"url": url, **kwargs}
        return await self.call_tool("process_file", arguments)
    
    async def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ"""
        async with self.session.post(
            f"{self.base_url}/mcp/tools/{tool_name}",
            json={"arguments": arguments}
        ) as resp:
            resp.raise_for_status()
            return await resp.json()

# ä½¿ç”¨ä¾‹
async def demo():
    async with AdvancedCrawl4AIMCPClient() as client:
        # åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’ç¢ºèª
        tools = await client.get_tools()
        print(f"åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«: {len(tools)}å€‹")
        
        # Webãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°
        crawl_result = await client.crawl_webpage(
            "https://httpbin.org/json",
            generate_markdown=True
        )
        
        # YouTubeå­—å¹•æŠ½å‡º
        youtube_result = await client.extract_youtube_transcript(
            "https://www.youtube.com/watch?v=UJnPNIoeqzI",
            languages=["ja", "en"],
            include_timestamps=True
        )
        
        # Googleæ¤œç´¢
        search_result = await client.search_google(
            "Python programming tutorial",
            num_results=3
        )
        
        print("ğŸ‰ ã™ã¹ã¦ã®æ“ä½œãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    asyncio.run(demo())
```

## ğŸ” ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼

### æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹

```json
{
  "isError": false,
  "content": {
    // ãƒ„ãƒ¼ãƒ«å›ºæœ‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
  }
}
```

### ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹

```json
{
  "isError": true,
  "content": "ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è©³ç´°"
}
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

### è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ

```bash
# ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹çŠ¶æ…‹ã§
python test_http_server.py

# ã‚«ã‚¹ã‚¿ãƒ URLæŒ‡å®š
python test_http_server.py --url http://192.168.1.100:8000
```

### æ‰‹å‹•ãƒ†ã‚¹ãƒˆ

```bash
# åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ
curl -X GET http://127.0.0.1:8000/

# ãƒ„ãƒ¼ãƒ«ä¸€è¦§å–å¾—
curl -X POST http://127.0.0.1:8000/mcp/tools

# ç°¡å˜ãªã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
curl -X POST http://127.0.0.1:8000/mcp/tools/crawl_url \
  -H "Content-Type: application/json" \
  -d '{"arguments": {"url": "https://httpbin.org/json"}}'
```

## âš™ï¸ è¨­å®šã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ç’°å¢ƒå¤‰æ•°

HTTP APIã‚µãƒ¼ãƒãƒ¼ã¯ã€é€šå¸¸ã®MCPã‚µãƒ¼ãƒãƒ¼ã¨åŒã˜ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

```bash
# LLMè¨­å®š
OPENAI_API_KEY=your-api-key
ANTHROPIC_API_KEY=your-api-key

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
FASTMCP_LOG_LEVEL=INFO
```

### ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. ãƒãƒ¼ãƒˆãŒä½¿ç”¨ä¸­

```bash
# åˆ¥ã®ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨
./run_http_server.sh --port 8080
```

#### 2. å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„

```bash
# å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯
./run_http_server.sh --external

# ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šç¢ºèª
sudo ufw status
```

#### 3. ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼

```bash
# ä¾å­˜é–¢ä¿‚å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

#### 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé…ã„

- LLMæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèª
- ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’DEBUGã«è¨­å®šã—ã¦è©³ç´°ã‚’ç¢ºèª

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### æœ¬ç•ªç’°å¢ƒã§ã®æ³¨æ„ç‚¹

1. **å¤–éƒ¨å…¬é–‹æ™‚ã®æ³¨æ„**
   - é©åˆ‡ãªãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š
   - ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã®ä½¿ç”¨ï¼ˆnginxç­‰ï¼‰
   - HTTPSåŒ–ã®æ¤œè¨

2. **ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡**
   - å¿…è¦ã«å¿œã˜ã¦èªè¨¼æ©Ÿèƒ½ã®è¿½åŠ 
   - ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å®Ÿè£…
   - IPã‚¢ãƒ‰ãƒ¬ã‚¹åˆ¶é™

3. **ãƒ­ã‚°ç®¡ç†**
   - é©åˆ‡ãªãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
   - æ©Ÿå¯†æƒ…å ±ã®ãƒã‚¹ã‚­ãƒ³ã‚°

## ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### æ¨å¥¨è¨­å®š

```bash
# é«˜è² è·ç’°å¢ƒã§ã®èµ·å‹•ä¾‹
python run_http_server.py \
  --host 0.0.0.0 \
  --port 8000 \
  --log-level WARNING
```

### ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

- CPUä½¿ç”¨ç‡ã®ç›£è¦–
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
- ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®æ¸¬å®š
- ã‚¨ãƒ©ãƒ¼ç‡ã®è¿½è·¡

## ğŸ“š é–¢é€£ãƒªã‚½ãƒ¼ã‚¹

- [FastMCP Documentation](https://github.com/jlowin/fastmcp)
- [Crawl4AI Documentation](https://crawl4ai.com/)
- [Model Context Protocol Specification](https://spec.modelcontextprotocol.io/)

## ğŸ¤ ã‚µãƒãƒ¼ãƒˆ

å•é¡Œã‚„è³ªå•ãŒã‚ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

1. **ãƒ­ã‚°ã®ç¢ºèª**: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
2. **ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ**: `python test_http_server.py`
3. **ç’°å¢ƒã®ç¢ºèª**: ä¾å­˜é–¢ä¿‚ã¨Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³
4. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: ã“ã®æ–‡æ›¸ã¨é–¢é€£ãƒªãƒ³ã‚¯

---

ã“ã®ã‚¬ã‚¤ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€Crawl4AI MCP HTTPã‚µãƒ¼ãƒãƒ¼ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼