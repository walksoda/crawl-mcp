#!/usr/bin/env python3
"""
Crawl4AI MCP HTTP Server
FastMCPã®StreamableHTTPãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä½¿ç”¨ã—ã¦HTTPã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªMCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
"""

import asyncio
import argparse
import logging
import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from crawl4ai_mcp.server import mcp


def setup_logging(log_level: str = "INFO"):
    """ãƒ­ã‚°è¨­å®šã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


async def run_http_server(host: str = "127.0.0.1", port: int = 8000, log_level: str = "INFO"):
    """HTTPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
    setup_logging(log_level)
    
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸš€ Crawl4AI MCP HTTPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
    logger.info(f"ğŸ“¡ ãƒ›ã‚¹ãƒˆ: {host}")
    logger.info(f"ğŸ”Œ ãƒãƒ¼ãƒˆ: {port}")
    logger.info(f"ğŸŒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: http://{host}:{port}")
    
    try:
        # HTTPãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆæ–°ã—ã„APIä½¿ç”¨ï¼‰
        try:
            await mcp.run_http_async(
                host=host,
                port=port,
                log_level=log_level.lower()
            )
        except AttributeError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¤ã„APIã‚’ä½¿ç”¨
            await mcp.run_streamable_http_async(
                host=host,
                port=port,
                log_level=log_level.lower()
            )
    except KeyboardInterrupt:
        logger.info("ğŸ“´ ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
    except Exception as e:
        logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        raise


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(
        description="Crawl4AI MCP HTTPã‚µãƒ¼ãƒãƒ¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python run_http_server.py                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§èµ·å‹• (127.0.0.1:8000)
  python run_http_server.py --host 0.0.0.0     # å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§èµ·å‹•
  python run_http_server.py --port 8080        # ãƒãƒ¼ãƒˆ8080ã§èµ·å‹•
  python run_http_server.py --log-level DEBUG  # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã§èµ·å‹•

HTTPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:
  GET  /                                        # ã‚µãƒ¼ãƒãƒ¼æƒ…å ±
  POST /mcp/tools                              # ãƒ„ãƒ¼ãƒ«ä¸€è¦§å–å¾—
  POST /mcp/tools/{tool_name}                  # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ
  POST /mcp/prompts                            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§å–å¾—
  POST /mcp/prompts/{prompt_name}              # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œ
  POST /mcp/resources                          # ãƒªã‚½ãƒ¼ã‚¹ä¸€è¦§å–å¾—
  POST /mcp/resources/{resource_uri}           # ãƒªã‚½ãƒ¼ã‚¹å–å¾—

ä¸»è¦ãªãƒ„ãƒ¼ãƒ«:
  crawl_url                                    # Webãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°
  extract_youtube_transcript                  # YouTubeå­—å¹•æŠ½å‡º
  search_google                               # Googleæ¤œç´¢
  process_file                                # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
  extract_structured_data                     # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        """
    )
    
    parser.add_argument(
        "--host",
        default="127.0.0.1",
        help="ãƒã‚¤ãƒ³ãƒ‰ã™ã‚‹ãƒ›ã‚¹ãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 127.0.0.1, å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯: 0.0.0.0)"
    )
    
    parser.add_argument(
        "--port",
        type=int,
        default=8000,
        help="ãƒã‚¤ãƒ³ãƒ‰ã™ã‚‹ãƒãƒ¼ãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8000)"
    )
    
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: INFO)"
    )
    
    args = parser.parse_args()
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è­¦å‘Š
    if args.host == "0.0.0.0":
        print("âš ï¸  è­¦å‘Š: å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªè¨­å®šã§èµ·å‹•ã—ã¾ã™")
        print("   é©åˆ‡ãªãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        print()
    
    print("ğŸ¯ Crawl4AI MCP HTTPã‚µãƒ¼ãƒãƒ¼")
    print(f"ğŸ“ ã‚¢ãƒ‰ãƒ¬ã‚¹: http://{args.host}:{args.port}")
    print("ğŸ“š APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: /docs (åˆ©ç”¨å¯èƒ½ãªå ´åˆ)")
    print("ğŸ›‘ åœæ­¢: Ctrl+C")
    print()
    
    try:
        asyncio.run(run_http_server(
            host=args.host,
            port=args.port,
            log_level=args.log_level
        ))
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()